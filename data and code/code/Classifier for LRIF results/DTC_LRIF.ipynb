{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "c_time = time.strftime(\"%Y%m%d_%H%M%S\", time.localtime())\n",
    "c_time_m = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 参数\n",
    "Version = 'V3.2'\n",
    "EPOCH = 1000\n",
    "INPUT_X = 'Features_94_343.csv'\n",
    "INPUT_Y = 'Values_94.csv'\n",
    "INPUT_TITLE = 'Title_343.csv'\n",
    "FIND_SPLIT = True\n",
    "INPUT_SPLIT = '100.0_Split.csv'\n",
    "SAVE_NAME = 'DTC_FeatureImportance_'+c_time+'.png'\n",
    "PLOT_NAME3 = 'DTC_ROC_'+c_time\n",
    "PLOT_NAME4 = 'DTC_CV_LOOP_'+c_time+'.png'\n",
    "SUPTITLE = 'DTC on '+INPUT_X+' and '+INPUT_Y+'\\nEPOCH:'+str(EPOCH)\n",
    "LOG_NAME = 'DTC_Log_'+c_time+'.txt'\n",
    "CV_LOOP_EPOCH = 300\n",
    "FOLD = 6\n",
    "TRAIN_TEST_SPLIT = 0.85\n",
    "INPUT_LRIF = 'LRIF_148_343.csv'\n",
    "INPUT_LRIF_LIST = 'LRIF_title_148.csv'\n",
    "LRIF_NAME = 'LRIF_Test_DTC_'+c_time+'.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.loadtxt(INPUT_X, delimiter=',')\n",
    "y = np.loadtxt(INPUT_Y)\n",
    "title = np.loadtxt(INPUT_TITLE, dtype='str')\n",
    "print('X:', X.shape, '   y:', y.shape)\n",
    "lrif_test = np.loadtxt(INPUT_LRIF, delimiter=',')\n",
    "print(lrif_test.shape)\n",
    "lrif_list = np.loadtxt(INPUT_LRIF_LIST, dtype='str', delimiter='#').reshape(lrif_test.shape[0], 1)\n",
    "count_m = np.zeros((lrif_test.shape[0], 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import graphviz\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "if FIND_SPLIT:\n",
    "    DIR = 'DTC_'+Version+'_FindSplit_'+c_time\n",
    "else:\n",
    "    DIR = 'DTC_'+Version+'_TestSplit_'+c_time\n",
    "os.mkdir(DIR)\n",
    "PLOT_NAME4 = Path('.', DIR, PLOT_NAME4)\n",
    "LRIF_NAME = Path('.', DIR, LRIF_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 打乱和切分数据集\n",
    "point = round(X.shape[0]*TRAIN_TEST_SPLIT)\n",
    "if not FIND_SPLIT:\n",
    "    permutation = np.loadtxt(INPUT_SPLIT).astype(int).flatten().tolist()\n",
    "    train_idx = []\n",
    "    test_idx = []\n",
    "    for i in range(X.shape[0]):\n",
    "        if i in permutation:\n",
    "            train_idx.append(i)\n",
    "        else:\n",
    "            test_idx.append(i)\n",
    "    X_train = X[train_idx, :]\n",
    "    y_train = y[train_idx]\n",
    "    X_test = X[test_idx, :]\n",
    "    y_test = y[test_idx]\n",
    "    perm_train = np.random.permutation(X_train.shape[0])\n",
    "    X_train = X_train[perm_train, :]\n",
    "    y_train = y_train[perm_train]\n",
    "    perm_test = np.random.permutation(X_test.shape[0])\n",
    "    X_test = X_test[perm_test, :]\n",
    "    y_test = y_test[perm_test]\n",
    "else:\n",
    "    permutation = np.random.permutation(y.shape[0])\n",
    "    X_train = X[permutation[:point], :]\n",
    "    y_train = y[permutation[:point]]\n",
    "    X_test = X[permutation[point:], :]\n",
    "    y_test = y[permutation[point:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cm_plot(y, yp, path): \n",
    "    cm = confusion_matrix(y, yp) #混淆矩阵\n",
    "    plt.figure(figsize=(5,5), dpi=300)\n",
    "    plt.matshow(cm, cmap=plt.cm.Greens) #画混淆矩阵图，配色风格使用cm.Greens，更多风格请参考官网。\n",
    "    plt.colorbar() #颜色标签 \n",
    "    for x in range(len(cm)): #数据标签\n",
    "        for y in range(len(cm)):\n",
    "            plt.annotate(cm[x,y], xy=(x, y), horizontalalignment='center', verticalalignment='center')\n",
    "    plt.ylabel('True label', fontsize=15) #坐标轴标签\n",
    "    plt.xlabel('Predicted label', fontsize=15) #坐标轴标签\n",
    "    plt.savefig(path, bbox_inches='tight', dpi=300)\n",
    "    plt.clf()\n",
    "    plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 搭建随机森林模型\n",
    "tuned_parameters = [{'min_impurity_decrease': [0.01], 'max_depth': [4, 5, None], \n",
    "                     'max_features': [0.95], 'max_leaf_nodes': [4, 5, None], 'class_weight': ['balanced'], \n",
    "                     'min_samples_leaf': [2, 3], 'min_samples_split': [1, 2, 3]}]\n",
    "dtc = DecisionTreeClassifier()\n",
    "clf = GridSearchCV(dtc, tuned_parameters, verbose=1, scoring=None, cv=6, n_jobs=-1)\n",
    "clf.fit(X, y)\n",
    "clf_new = clf.best_estimator_\n",
    "best_p = clf.best_params_\n",
    "paras = clf_new.get_params()\n",
    "print(best_p)\n",
    "acc_unique = clf_new.score(X_test, y_test)\n",
    "print('Current accuracy:', acc_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "f_i = np.zeros((title.shape[0], 1))\n",
    "mse_list = []\n",
    "acc_list = []\n",
    "mean_acc_list = []\n",
    "min_mse = 999.9\n",
    "for _ in range(EPOCH):\n",
    "    # 打乱和切分数据集\n",
    "    if FIND_SPLIT:\n",
    "        permutation = np.random.permutation(y.shape[0])\n",
    "        X_train = X[permutation[:point], :]\n",
    "        y_train = y[permutation[:point]]\n",
    "        X_test = X[permutation[point:], :]\n",
    "        y_test = y[permutation[point:]]\n",
    "    else:\n",
    "        perm_train = np.random.permutation(X_train.shape[0])\n",
    "        X_train = X_train[perm_train, :]\n",
    "        y_train = y_train[perm_train]\n",
    "        perm_test = np.random.permutation(X_test.shape[0])\n",
    "        X_test = X_test[perm_test, :]\n",
    "        y_test = y_test[perm_test]\n",
    "    # print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "    clf_new = DecisionTreeClassifier()\n",
    "    for k, v in paras.items():\n",
    "        clf_new.set_params(**{k: v})\n",
    "    # 拟合模型\n",
    "    clf_new.fit(X_train, y_train)\n",
    "    # 计算损失\n",
    "    y_pred = clf_new.predict(X_test)\n",
    "    lrif_predict = clf_new.predict(lrif_test)\n",
    "    for i in range(lrif_test.shape[0]):\n",
    "        if lrif_predict[i]==1:\n",
    "            count_m[i, 0] += 1\n",
    "        else:\n",
    "            count_m[i, 1] += 1\n",
    "    acc_count = 0\n",
    "    for i in range(X_test.shape[0]):\n",
    "        if y_pred[i]==y_test[i]:\n",
    "            acc_count += 1\n",
    "    acc = acc_count*100/X_test.shape[0]\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mse_list.append(mse)\n",
    "    acc_list.append(acc)\n",
    "    mean_acc = np.mean(acc_list)\n",
    "    mean_acc_list.append(mean_acc)\n",
    "    print('Round:', _+1, \"MSE: %.4f\" % mse, '  Accuracy: %.4f' % acc, '  current mean acc: %.4f' % mean_acc)\n",
    "    # 计算特征重要度\n",
    "    feature_importance = np.array(clf_new.feature_importances_).reshape(title.shape[0], 1)\n",
    "    f_i = f_i+feature_importance*acc\n",
    "    if mse<min_mse or mse<0.15:\n",
    "        if mse<min_mse:\n",
    "            min_mse = mse\n",
    "        clf_name = str(round(min_mse, 4))+'_DTC.pkl'\n",
    "        clf_name = Path('.', DIR, clf_name)\n",
    "        joblib.dump(clf_new, clf_name)\n",
    "        pred = clf_new.predict(X_test)\n",
    "        PLOT_NAME2 = str(round(acc, 4))+'_DTC_ConfusionMatrix_'+c_time+'.png'\n",
    "        PLOT_NAME2 = Path('.', DIR, PLOT_NAME2)\n",
    "        cm_plot(y_test, pred, PLOT_NAME2)\n",
    "        dot_data = tree.export_graphviz(clf_new, out_file=None,\n",
    "                      feature_names=title,  \n",
    "                      class_names=['1', '0'],  \n",
    "                      filled=True, rounded=True,  \n",
    "                      special_characters=True)  \n",
    "        graph = graphviz.Source(dot_data)  \n",
    "        graph.render(filename=str(round(acc, 4))+'_DTC', directory=DIR, format='png')\n",
    "        # 保存切分数据\n",
    "        if FIND_SPLIT:\n",
    "            SPLIT_NAME = str(round(acc, 4))+'_Split.csv'\n",
    "            SPLIT_NAME = Path('.', DIR, SPLIT_NAME)\n",
    "            np.savetxt(SPLIT_NAME, np.array(permutation[:point]).reshape(point, 1), fmt='%d')\n",
    "print('Mean accuracy:', np.mean(acc_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cv_acc_list = []\n",
    "cv_mean_acc_list = []\n",
    "for _ in range(CV_LOOP_EPOCH):\n",
    "    # 打乱训练集并分割\n",
    "    permutation = np.random.permutation(y.shape[0])\n",
    "    X = X[permutation, :]\n",
    "    y = y[permutation]\n",
    "    clf_brand_new = DecisionTreeClassifier()\n",
    "    for k, v in paras.items():\n",
    "        clf_brand_new.set_params(**{k: v})\n",
    "    scores = cross_val_score(clf_brand_new, X, y, cv=FOLD, n_jobs=-1)\n",
    "    cv_acc_list.append(np.mean(scores))\n",
    "    cv_mean_acc_list.append(np.mean(cv_acc_list))\n",
    "    print('round:', _+1, '  accuarcy: %.4f' % np.mean(scores), '  current mean acc: %.4f' % np.mean(cv_acc_list))\n",
    "print('Mean accuracy of CV-Loop:', np.mean(cv_acc_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "mu = np.mean(acc_list)\n",
    "sigma = np.std(acc_list)\n",
    "acc_array = np.array(acc_list).reshape(len(acc_list), 1)\n",
    "acc_sorted = np.sort(acc_array, axis=0)\n",
    "x_arg = np.linspace(1, acc_sorted.shape[0], acc_sorted.shape[0])\n",
    "plt.figure(figsize=(6, 6), dpi=250)\n",
    "n, bins, patches = plt.hist(acc_sorted, bins=30, density=1)\n",
    "acc_N = norm.pdf(bins, mu, sigma)\n",
    "plt.plot(bins, acc_N)\n",
    "plt.title('Distribution of Acc\\nMean Acc: '+str(round(np.mean(acc_list), 3))+'  Max Acc: '+str(round(max(acc_list), 3)), fontsize=18)\n",
    "plt.ylabel('Possibility', fontsize=15)\n",
    "plt.xlabel('Acc', fontsize=15)\n",
    "PLOT_NAME6 = 'Acc_Distribution_DTC_NormalLoop_'+c_time+'.png'\n",
    "PLOT_NAME6 = Path('.', DIR, PLOT_NAME6)\n",
    "plt.savefig(PLOT_NAME6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = np.mean(cv_acc_list)\n",
    "sigma = np.std(cv_acc_list)\n",
    "acc_array = np.array(cv_acc_list).reshape(len(cv_acc_list), 1)\n",
    "acc_sorted = np.sort(acc_array, axis=0)\n",
    "x_arg = np.linspace(1, acc_sorted.shape[0], acc_sorted.shape[0])\n",
    "plt.figure(figsize=(6, 6), dpi=250)\n",
    "n, bins, patches = plt.hist(acc_sorted, bins=30, density=1)\n",
    "acc_N = norm.pdf(bins, mu, sigma)\n",
    "plt.plot(bins, acc_N)\n",
    "plt.title('Distribution of Acc\\nMean Acc: '+str(round(np.mean(cv_acc_list), 3))+'  Max Acc: '+str(round(max(cv_acc_list), 3)), fontsize=18)\n",
    "plt.ylabel('Possibility', fontsize=15)\n",
    "plt.xlabel('CV Mean Acc', fontsize=15)\n",
    "PLOT_NAME7 = 'Acc_Distribution_DTC_CVLoop_'+c_time+'.png'\n",
    "PLOT_NAME7 = Path('.', DIR, PLOT_NAME7)\n",
    "plt.savefig(PLOT_NAME7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(11, 8), dpi=250)\n",
    "f_i_temp = f_i.copy()\n",
    "# 计算相对重要度\n",
    "f_i_temp[:, 0] = 100.0 * (f_i_temp[:, 0]/(max(f_i_temp[:, 0])-min(f_i_temp[:, 0])))\n",
    "sorted_idx = np.argsort(-f_i_temp[:, 0])\n",
    "pos = np.arange(sorted_idx.shape[0]) + .5\n",
    "plt.barh(pos[:10, ], f_i_temp[sorted_idx[:10, ], 0].flatten().tolist(), align='center')\n",
    "plt.yticks(pos[:10, ], title[sorted_idx[:10, ]])\n",
    "plt.xlabel('Relative Importance', fontsize=16)\n",
    "plt.title('Variable Importance (First 10)', fontsize=18)\n",
    "SUPTITLE = SUPTITLE+' Mean Acc: '+str(np.mean(acc_list))\n",
    "plt.suptitle(SUPTITLE, fontsize=18)\n",
    "SAVE_NAME = Path('.', DIR, SAVE_NAME)\n",
    "plt.savefig(SAVE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(11,11), dpi=300)\n",
    "plt.subplot(211)\n",
    "x_idx = np.linspace(1, len(acc_list), len(acc_list)).tolist()\n",
    "plt.scatter(x_idx, acc_list, color='r')\n",
    "plt.plot(x_idx, mean_acc_list, 'b:')\n",
    "plt.title('Acc Curve of Normal Loop', fontsize=18)\n",
    "plt.ylabel('Accuracy', fontsize=15)\n",
    "plt.xlabel('Epoch', fontsize=15)\n",
    "plt.subplot(212)\n",
    "plt.title('Acc Curve of CV-Loop', fontsize=18)\n",
    "cv_x_idx = np.linspace(1, len(cv_acc_list), len(cv_acc_list)).tolist()\n",
    "plt.scatter(cv_x_idx, cv_acc_list, color='r')\n",
    "plt.plot(cv_x_idx, cv_mean_acc_list, 'b:')\n",
    "plt.ylabel('Accuracy', fontsize=15)\n",
    "plt.xlabel('Epoch', fontsize=15)\n",
    "plt.suptitle('DecisionTreeClassifier Accuracy-Epoch Curves\\n'+'Epoch of normal loop: '+\n",
    "             str(EPOCH)+'   Epoch of CV-loop: '+str(CV_LOOP_EPOCH), fontsize=20)\n",
    "plt.savefig(PLOT_NAME4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_m = np.hstack((lrif_list, count_m))\n",
    "np.savetxt(LRIF_NAME, count_m, fmt='%s', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOG_NAME = Path('.', DIR, LOG_NAME)\n",
    "f1 = open(LOG_NAME, 'w+')\n",
    "f1.write('DecisionTreeClassifier Log\\n\\n')\n",
    "f1.write('Input data: '+INPUT_X+' and '+INPUT_Y+'\\n')\n",
    "f1.write('Data Shape:'+str(X.shape)+', '+str(y.shape)+'\\n\\n')\n",
    "f1.write('Epoch of normal loop: '+str(EPOCH)+'\\n')\n",
    "f1.write('Epoch of CV-loop: '+str(CV_LOOP_EPOCH)+'\\n')\n",
    "f1.write('Fold number of CV-loop: '+str(FOLD)+'\\n\\n')\n",
    "f1.write('Best parameters from CV: '+str(best_p)+'\\n\\n')\n",
    "f1.write('Classifier parameters:\\n')\n",
    "f1.write(str(paras)+'\\n\\n')\n",
    "f1.write('Mean accuracy of Normal Loop: '+str(np.mean(acc_list))+'\\n')\n",
    "f1.write('Mean accuracy of CV-Loop: '+str(np.mean(cv_acc_list))+'\\n\\n')\n",
    "f1.write('Mean MSE:'+str(np.mean(mse_list))+'\\n')\n",
    "for i in range(30):\n",
    "    f1.write('name:'+str(title[sorted_idx[i, ], ])+'   value:'+str(f_i_temp[sorted_idx[i, ], 0])+'\\n')\n",
    "f1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm, datasets\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import plot_roc_curve\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "n_samples, n_features = X.shape\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "rand_state = np.random.randint(5000)\n",
    "print('Random state:', rand_state)\n",
    "cv = ShuffleSplit(n_splits=10, test_size=.15, random_state=rand_state)\n",
    "\n",
    "tprs = []\n",
    "aucs = []\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "\n",
    "plt.figure(figsize=(8,5), dpi=300)\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "clf_list = []\n",
    "for i in range(10):\n",
    "    clf_list.append(DecisionTreeClassifier())\n",
    "\n",
    "for i, (train, test) in enumerate(cv.split(X, y)):\n",
    "    for k, v in paras.items():\n",
    "        # clf_brand_new_1.set_params(**{k: v})\n",
    "        clf_list[i].set_params(**{k: v})\n",
    "    clf_list[i].fit(X[train], y[train])\n",
    "    viz = plot_roc_curve(clf_list[i], X[test], y[test],\n",
    "                         name='ROC fold {}'.format(i),\n",
    "                         alpha=0.3, lw=1, ax=ax)\n",
    "    interp_tpr = np.interp(mean_fpr, viz.fpr, viz.tpr)\n",
    "    interp_tpr[0] = 0.0\n",
    "    tprs.append(interp_tpr)\n",
    "    aucs.append(viz.roc_auc)\n",
    "\n",
    "ax.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r',\n",
    "        label='Chance', alpha=.8)\n",
    "\n",
    "mean_tpr = np.mean(tprs, axis=0)\n",
    "mean_tpr[-1] = 1.0\n",
    "mean_auc = auc(mean_fpr, mean_tpr)\n",
    "std_auc = np.std(aucs)\n",
    "ax.plot(mean_fpr, mean_tpr, color='b',\n",
    "        label=r'Mean ROC (AUC = %0.2f $\\pm$ %0.2f)' % (mean_auc, std_auc),\n",
    "        lw=2, alpha=.8)\n",
    "\n",
    "std_tpr = np.std(tprs, axis=0)\n",
    "tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "ax.fill_between(mean_fpr, tprs_lower, tprs_upper, color='grey', alpha=.2,\n",
    "                label=r'$\\pm$ 1 std. dev.')\n",
    "\n",
    "ax.set(xlim=[-0.05, 1.05], ylim=[-0.05, 1.05],\n",
    "       title=\"DTC Receiver operating characteristic curve\\n\"+'Random state: '+str(rand_state))\n",
    "ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\n",
    "# plt.show()\n",
    "PLOT_NAME3_n = PLOT_NAME3+'_'+str(rand_state)+'.png'\n",
    "PLOT_NAME3_n = Path('.', DIR, PLOT_NAME3_n)\n",
    "plt.savefig(PLOT_NAME3_n, bbox_inches='tight', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(clf_new, X, y, cv=3)\n",
    "scores"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PythonForDYH",
   "language": "python",
   "name": "dyhpy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
